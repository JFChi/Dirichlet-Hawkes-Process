{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('result/particles.pkl','r') as f:\n",
    "    particles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../id2word.json','r') as f:\n",
    "    id2word = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have verified that all the weights are the same\n",
    "particle = particles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_cnt = Counter(particle.docs2cluster_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document number: 48986\n",
      "cluster number: 681\n"
     ]
    }
   ],
   "source": [
    "print('document number: %d' % len(particle.docs2cluster_ID) )\n",
    "print('cluster number: %d' % len(cls_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 clusters:\n",
      "cluster 2: 18427 documents\n",
      "cluster 3: 8451 documents\n",
      "cluster 4: 5901 documents\n",
      "cluster 28: 4614 documents\n",
      "cluster 10: 2394 documents\n",
      "cluster 14: 2336 documents\n",
      "cluster 34: 1872 documents\n",
      "cluster 312: 972 documents\n",
      "cluster 561: 738 documents\n",
      "cluster 435: 592 documents\n"
     ]
    }
   ],
   "source": [
    "print('top 10 clusters:')\n",
    "for cls_id, count in cls_cnt.most_common(10):\n",
    "    print('cluster %d: %d documents' %( cls_id, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'white', 14879.0)\n",
      "(u'women', 14775.0)\n",
      "(u'obama', 12390.0)\n",
      "(u'elect', 12183.0)\n",
      "(u'citi', 11841.0)\n",
      "(u'famili', 11703.0)\n",
      "(u'parti', 11524.0)\n",
      "(u'america', 11048.0)\n",
      "(u'life', 11015.0)\n",
      "(u'compani', 10488.0)\n",
      "(u'school', 10259.0)\n",
      "(u'power', 10231.0)\n",
      "(u'media', 10011.0)\n",
      "(u'war', 9997.0)\n",
      "(u'im', 9689.0)\n",
      "(u'stori', 9643.0)\n",
      "(u'administr', 9589.0)\n",
      "(u'polici', 9510.0)\n",
      "(u'talk', 9449.0)\n",
      "(u'feel', 9409.0)\n",
      "(u'million', 9393.0)\n",
      "(u'leader', 9384.0)\n",
      "(u'chang', 9306.0)\n",
      "(u'play', 9244.0)\n",
      "(u'washington', 9181.0)\n",
      "(u'home', 8955.0)\n",
      "(u'york', 8828.0)\n",
      "(u'plan', 8817.0)\n",
      "(u'place', 8682.0)\n",
      "(u'busi', 8661.0)\n",
      "(u'post', 8517.0)\n",
      "(u'forc', 8446.0)\n",
      "(u'book', 8444.0)\n",
      "(u'immigr', 8408.0)\n",
      "(u'man', 8355.0)\n",
      "(u'organ', 8294.0)\n",
      "(u'member', 8240.0)\n",
      "(u'black', 8232.0)\n",
      "(u'job', 8160.0)\n",
      "(u'student', 8091.0)\n",
      "(u'turn', 8083.0)\n",
      "(u'secur', 8080.0)\n",
      "(u'attack', 8076.0)\n",
      "(u'love', 7982.0)\n",
      "(u'order', 7980.0)\n",
      "(u'vote', 7939.0)\n",
      "(u'film', 7917.0)\n",
      "(u'law', 7901.0)\n",
      "(u'commun', 7868.0)\n",
      "(u'univers', 7729.0)\n",
      "(u'didnt', 7615.0)\n",
      "(u'protest', 7579.0)\n",
      "(u'critic', 7500.0)\n",
      "(u'lot', 7442.0)\n",
      "(u'great', 7429.0)\n",
      "(u'face', 7402.0)\n",
      "(u'percent', 7311.0)\n",
      "(u'left', 7270.0)\n",
      "(u'find', 7269.0)\n",
      "(u'interest', 7261.0)\n",
      "(u'open', 7258.0)\n",
      "(u'deal', 7235.0)\n",
      "(u'meet', 7200.0)\n",
      "(u'social', 7176.0)\n",
      "(u'set', 7138.0)\n",
      "(u'he', 7082.0)\n",
      "(u'friend', 7022.0)\n",
      "(u'case', 6998.0)\n",
      "(u'read', 6956.0)\n",
      "(u'found', 6898.0)\n",
      "(u'build', 6827.0)\n",
      "(u'democrat', 6818.0)\n",
      "(u'march', 6799.0)\n",
      "(u'run', 6777.0)\n",
      "(u'men', 6768.0)\n",
      "(u'twitter', 6753.0)\n",
      "(u'\\t', 6702.0)\n",
      "(u'children', 6524.0)\n",
      "(u'execut', 6511.0)\n",
      "(u'take', 6508.0)\n",
      "(u'ask', 6489.0)\n",
      "(u'right', 6480.0)\n",
      "(u'intern', 6476.0)\n",
      "(u'fact', 6440.0)\n",
      "(u'kind', 6413.0)\n",
      "(u'claim', 6394.0)\n",
      "(u'histori', 6368.0)\n",
      "(u'muslim', 6334.0)\n",
      "(u'speech', 6307.0)\n",
      "(u'republican', 6279.0)\n",
      "(u'human', 6226.0)\n",
      "(u'statement', 6189.0)\n",
      "(u'give', 6156.0)\n",
      "(u'word', 6149.0)\n",
      "(u'view', 6145.0)\n",
      "(u'major', 6136.0)\n",
      "(u'night', 6130.0)\n",
      "(u'conserv', 6127.0)\n",
      "(u'hope', 6120.0)\n",
      "(u'polic', 6110.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster 2\n",
    "specified_cls = particle.clusters[2]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'republican', 21637.0)\n",
      "(u'democrat', 19678.0)\n",
      "(u'senat', 17607.0)\n",
      "(u'administr', 14323.0)\n",
      "(u'white', 12598.0)\n",
      "(u'court', 12182.0)\n",
      "(u'obama', 11508.0)\n",
      "(u'elect', 10882.0)\n",
      "(u'law', 10593.0)\n",
      "(u'vote', 10500.0)\n",
      "(u'order', 10186.0)\n",
      "(u'russia', 9829.0)\n",
      "(u'russian', 9346.0)\n",
      "(u'plan', 8845.0)\n",
      "(u'feder', 8536.0)\n",
      "(u'polici', 8136.0)\n",
      "(u'intellig', 8127.0)\n",
      "(u'secur', 8028.0)\n",
      "(u'depart', 8001.0)\n",
      "(u'investig', 7938.0)\n",
      "(u'bill', 7928.0)\n",
      "(u'committe', 7700.0)\n",
      "(u'washington', 7258.0)\n",
      "(u'parti', 7251.0)\n",
      "(u'congress', 7182.0)\n",
      "(u'clinton', 7131.0)\n",
      "(u'health', 6989.0)\n",
      "(u'execut', 6968.0)\n",
      "(u'rule', 6883.0)\n",
      "(u'care', 6487.0)\n",
      "(u'agenc', 6410.0)\n",
      "(u'secretari', 6291.0)\n",
      "(u'case', 6100.0)\n",
      "(u'act', 5988.0)\n",
      "(u'justic', 5917.0)\n",
      "(u'judg', 5783.0)\n",
      "(u'member', 5689.0)\n",
      "(u'confirm', 5627.0)\n",
      "(u'leader', 5612.0)\n",
      "(u'tax', 5599.0)\n",
      "(u'major', 5485.0)\n",
      "(u'inform', 5348.0)\n",
      "(u'meet', 5207.0)\n",
      "(u'press', 5072.0)\n",
      "(u'foreign', 5049.0)\n",
      "(u'power', 4969.0)\n",
      "(u'statement', 4961.0)\n",
      "(u'gorsuch', 4947.0)\n",
      "(u'chang', 4935.0)\n",
      "(u'media', 4920.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[3]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 50\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'polic', 13005.0)\n",
      "(u'attack', 8136.0)\n",
      "(u'immigr', 6902.0)\n",
      "(u'citi', 6354.0)\n",
      "(u'kill', 6096.0)\n",
      "(u'law', 5224.0)\n",
      "(u'forc', 5094.0)\n",
      "(u'case', 5053.0)\n",
      "(u'court', 4717.0)\n",
      "(u'investig', 4572.0)\n",
      "(u'charg', 4558.0)\n",
      "(u'arrest', 4488.0)\n",
      "(u'famili', 4419.0)\n",
      "(u'secur', 4284.0)\n",
      "(u'depart', 4190.0)\n",
      "(u'man', 4104.0)\n",
      "(u'feder', 4052.0)\n",
      "(u'crime', 3773.0)\n",
      "(u'author', 3724.0)\n",
      "(u'enforc', 3607.0)\n",
      "(u'death', 3460.0)\n",
      "(u'statement', 3353.0)\n",
      "(u'member', 3327.0)\n",
      "(u'border', 3229.0)\n",
      "(u'victim', 3152.0)\n",
      "(u'found', 3145.0)\n",
      "(u'gun', 3065.0)\n",
      "(u'shoot', 3041.0)\n",
      "(u'syria', 3019.0)\n",
      "(u'militari', 3015.0)\n",
      "(u'crimin', 3001.0)\n",
      "(u'order', 2999.0)\n",
      "(u'home', 2955.0)\n",
      "(u'commun', 2917.0)\n",
      "(u'attorney', 2912.0)\n",
      "(u'islam', 2892.0)\n",
      "(u'administr', 2868.0)\n",
      "(u'agent', 2843.0)\n",
      "(u'video', 2789.0)\n",
      "(u'children', 2780.0)\n",
      "(u'prison', 2744.0)\n",
      "(u'fire', 2714.0)\n",
      "(u'school', 2668.0)\n",
      "(u'claim', 2647.0)\n",
      "(u'releas', 2627.0)\n",
      "(u'local', 2542.0)\n",
      "(u'incid', 2488.0)\n",
      "(u'texa', 2478.0)\n",
      "(u'murder', 2475.0)\n",
      "(u'face', 2459.0)\n",
      "(u'area', 2447.0)\n",
      "(u'friday', 2403.0)\n",
      "(u'suspect', 2393.0)\n",
      "(u'carri', 2366.0)\n",
      "(u'execut', 2322.0)\n",
      "(u'counti', 2322.0)\n",
      "(u'illeg', 2313.0)\n",
      "(u'drug', 2305.0)\n",
      "(u'justic', 2286.0)\n",
      "(u'weapon', 2282.0)\n",
      "(u'shot', 2269.0)\n",
      "(u'oper', 2266.0)\n",
      "(u'judg', 2251.0)\n",
      "(u'bomb', 2212.0)\n",
      "(u'polici', 2208.0)\n",
      "(u'respons', 2203.0)\n",
      "(u'deport', 2192.0)\n",
      "(u'post', 2187.0)\n",
      "(u'tuesday', 2181.0)\n",
      "(u'syrian', 2172.0)\n",
      "(u'number', 2149.0)\n",
      "(u'car', 2133.0)\n",
      "(u'fight', 2119.0)\n",
      "(u'prosecutor', 2078.0)\n",
      "(u'wednesday', 2075.0)\n",
      "(u'assault', 2072.0)\n",
      "(u'violenc', 2070.0)\n",
      "(u'breitbart', 2056.0)\n",
      "(u'strike', 2050.0)\n",
      "(u'white', 2041.0)\n",
      "(u'target', 2030.0)\n",
      "(u'york', 2021.0)\n",
      "(u'woman', 2016.0)\n",
      "(u'plan', 2015.0)\n",
      "(u'men', 2009.0)\n",
      "(u'stop', 1999.0)\n",
      "(u'happen', 1947.0)\n",
      "(u'protect', 1946.0)\n",
      "(u'ask', 1938.0)\n",
      "(u'place', 1938.0)\n",
      "(u'thursday', 1910.0)\n",
      "(u'cnn', 1895.0)\n",
      "(u'protest', 1892.0)\n",
      "(u'inform', 1888.0)\n",
      "(u'ice', 1880.0)\n",
      "(u'monday', 1876.0)\n",
      "(u'action', 1875.0)\n",
      "(u'hospit', 1868.0)\n",
      "(u'act', 1859.0)\n",
      "(u'intern', 1830.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[4]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'compani', 15540.0)\n",
      "(u'percent', 10881.0)\n",
      "(u'billion', 7069.0)\n",
      "(u'market', 6569.0)\n",
      "(u'bank', 6159.0)\n",
      "(u'trade', 5262.0)\n",
      "(u'million', 5210.0)\n",
      "(u'busi', 5078.0)\n",
      "(u'tax', 4674.0)\n",
      "(u'share', 4244.0)\n",
      "(u'job', 4177.0)\n",
      "(u'rate', 4038.0)\n",
      "(u'price', 3926.0)\n",
      "(u'investor', 3856.0)\n",
      "(u'invest', 3814.0)\n",
      "(u'deal', 3813.0)\n",
      "(u'financi', 3610.0)\n",
      "(u'plan', 3607.0)\n",
      "(u'industri', 3460.0)\n",
      "(u'expect', 3407.0)\n",
      "(u'execut', 3210.0)\n",
      "(u'uber', 3181.0)\n",
      "(u'china', 3180.0)\n",
      "(u'product', 3165.0)\n",
      "(u'economi', 3141.0)\n",
      "(u'firm', 3133.0)\n",
      "(u'fund', 3093.0)\n",
      "(u'sale', 3043.0)\n",
      "(u'growth', 2991.0)\n",
      "(u'stock', 2969.0)\n",
      "(u'worker', 2946.0)\n",
      "(u'econom', 2855.0)\n",
      "(u'servic', 2849.0)\n",
      "(u'increas', 2769.0)\n",
      "(u'manag', 2736.0)\n",
      "(u'cut', 2702.0)\n",
      "(u'car', 2658.0)\n",
      "(u'polici', 2650.0)\n",
      "(u'feder', 2594.0)\n",
      "(u'global', 2490.0)\n",
      "(u'pay', 2470.0)\n",
      "(u'technolog', 2426.0)\n",
      "(u'data', 2420.0)\n",
      "(u'chief', 2419.0)\n",
      "(u'wednesday', 2348.0)\n",
      "(u'administr', 2286.0)\n",
      "(u'rule', 2266.0)\n",
      "(u'interest', 2257.0)\n",
      "(u'consum', 2245.0)\n",
      "(u'cost', 2213.0)\n",
      "(u'sourc', 2156.0)\n",
      "(u'declin', 2153.0)\n",
      "(u'major', 2132.0)\n",
      "(u'offer', 2120.0)\n",
      "(u'money', 2102.0)\n",
      "(u'analyst', 2084.0)\n",
      "(u'regul', 2071.0)\n",
      "(u'system', 2054.0)\n",
      "(u'meet', 2022.0)\n",
      "(u'tuesday', 2011.0)\n",
      "(u'close', 2010.0)\n",
      "(u'sign', 2002.0)\n",
      "(u'oper', 1985.0)\n",
      "(u'secur', 1976.0)\n",
      "(u'develop', 1966.0)\n",
      "(u'custom', 1965.0)\n",
      "(u'chang', 1960.0)\n",
      "(u'capit', 1947.0)\n",
      "(u'rais', 1938.0)\n",
      "(u'york', 1937.0)\n",
      "(u'hold', 1930.0)\n",
      "(u'appl', 1930.0)\n",
      "(u'target', 1923.0)\n",
      "(u'edit', 1912.0)\n",
      "(u'labor', 1884.0)\n",
      "(u'import', 1877.0)\n",
      "(u'big', 1876.0)\n",
      "(u'inflat', 1854.0)\n",
      "(u'buy', 1851.0)\n",
      "(u'number', 1796.0)\n",
      "(u'sell', 1780.0)\n",
      "(u'quarter', 1780.0)\n",
      "(u'dollar', 1779.0)\n",
      "(u'comment', 1776.0)\n",
      "(u'fed', 1770.0)\n",
      "(u'revenu', 1765.0)\n",
      "(u'profit', 1764.0)\n",
      "(u'high', 1757.0)\n",
      "(u'retail', 1742.0)\n",
      "(u'program', 1736.0)\n",
      "(u'ceo', 1709.0)\n",
      "(u'store', 1705.0)\n",
      "(u'agreement', 1697.0)\n",
      "(u'employe', 1685.0)\n",
      "(u'announc', 1656.0)\n",
      "(u'spend', 1652.0)\n",
      "(u'creat', 1646.0)\n",
      "(u'amazon', 1610.0)\n",
      "(u'privat', 1603.0)\n",
      "(u'statement', 1602.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[28]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'game', 7426.0)\n",
      "(u'team', 6001.0)\n",
      "(u'play', 5258.0)\n",
      "(u'player', 4575.0)\n",
      "(u'season', 4386.0)\n",
      "(u'win', 2988.0)\n",
      "(u'leagu', 2668.0)\n",
      "(u'coach', 2248.0)\n",
      "(u'final', 2196.0)\n",
      "(u'sport', 2005.0)\n",
      "(u'run', 1988.0)\n",
      "(u'he', 1936.0)\n",
      "(u'fan', 1752.0)\n",
      "(u'im', 1720.0)\n",
      "(u'ball', 1650.0)\n",
      "(u'open', 1611.0)\n",
      "(u'met', 1588.0)\n",
      "(u'yanke', 1586.0)\n",
      "(u'hit', 1458.0)\n",
      "(u'guy', 1429.0)\n",
      "(u'won', 1359.0)\n",
      "(u'big', 1356.0)\n",
      "(u'score', 1309.0)\n",
      "(u'manag', 1309.0)\n",
      "(u'left', 1296.0)\n",
      "(u'great', 1284.0)\n",
      "(u'night', 1274.0)\n",
      "(u'didnt', 1265.0)\n",
      "(u'field', 1239.0)\n",
      "(u'feel', 1234.0)\n",
      "(u'home', 1218.0)\n",
      "(u'lead', 1216.0)\n",
      "(u'nfl', 1195.0)\n",
      "(u'lot', 1182.0)\n",
      "(u'goal', 1157.0)\n",
      "(u'tournament', 1155.0)\n",
      "(u'bowl', 1153.0)\n",
      "(u'major', 1148.0)\n",
      "(u'defens', 1133.0)\n",
      "(u'shot', 1131.0)\n",
      "(u'footbal', 1131.0)\n",
      "(u'top', 1118.0)\n",
      "(u'pick', 1116.0)\n",
      "(u'knick', 1114.0)\n",
      "(u'sunday', 1112.0)\n",
      "(u'club', 1095.0)\n",
      "(u'minut', 1078.0)\n",
      "(u'man', 1057.0)\n",
      "(u'citi', 1036.0)\n",
      "(u'round', 1031.0)\n",
      "(u'career', 1025.0)\n",
      "(u'head', 1018.0)\n",
      "(u'super', 1015.0)\n",
      "(u'set', 1011.0)\n",
      "(u'million', 1003.0)\n",
      "(u'pitch', 1002.0)\n",
      "(u'match', 1001.0)\n",
      "(u'espn', 985.0)\n",
      "(u'talk', 978.0)\n",
      "(u'turn', 972.0)\n",
      "(u'chanc', 961.0)\n",
      "(u'titl', 947.0)\n",
      "(u'quarterback', 933.0)\n",
      "(u'giant', 925.0)\n",
      "(u'miss', 922.0)\n",
      "(u'playoff', 921.0)\n",
      "(u'basebal', 920.0)\n",
      "(u'champion', 910.0)\n",
      "(u'return', 906.0)\n",
      "(u'draft', 888.0)\n",
      "(u'patriot', 875.0)\n",
      "(u'championship', 875.0)\n",
      "(u'finish', 870.0)\n",
      "(u'pass', 857.0)\n",
      "(u'past', 848.0)\n",
      "(u'saturday', 845.0)\n",
      "(u'face', 839.0)\n",
      "(u'side', 838.0)\n",
      "(u'injuri', 822.0)\n",
      "(u'line', 818.0)\n",
      "(u'posit', 815.0)\n",
      "(u'victori', 808.0)\n",
      "(u'lost', 803.0)\n",
      "(u'deal', 803.0)\n",
      "(u'watch', 800.0)\n",
      "(u'appear', 799.0)\n",
      "(u'record', 798.0)\n",
      "(u'bradi', 797.0)\n",
      "(u'sign', 787.0)\n",
      "(u'hope', 777.0)\n",
      "(u'offens', 777.0)\n",
      "(u'expect', 773.0)\n",
      "(u'half', 771.0)\n",
      "(u'nba', 764.0)\n",
      "(u'anthoni', 761.0)\n",
      "(u'trade', 760.0)\n",
      "(u'fight', 756.0)\n",
      "(u'give', 753.0)\n",
      "(u'place', 750.0)\n",
      "(u'ask', 749.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[10]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'health', 4987.0)\n",
      "(u'studi', 4640.0)\n",
      "(u'research', 4296.0)\n",
      "(u'drug', 3867.0)\n",
      "(u'patient', 3344.0)\n",
      "(u'medic', 2961.0)\n",
      "(u'school', 2728.0)\n",
      "(u'care', 2688.0)\n",
      "(u'percent', 2655.0)\n",
      "(u'diseas', 2612.0)\n",
      "(u'children', 2593.0)\n",
      "(u'food', 2570.0)\n",
      "(u'doctor', 2511.0)\n",
      "(u'found', 2448.0)\n",
      "(u'women', 2442.0)\n",
      "(u'univers', 2259.0)\n",
      "(u'famili', 1991.0)\n",
      "(u'human', 1912.0)\n",
      "(u'cancer', 1892.0)\n",
      "(u'find', 1891.0)\n",
      "(u'test', 1889.0)\n",
      "(u'brain', 1861.0)\n",
      "(u'case', 1825.0)\n",
      "(u'hospit', 1761.0)\n",
      "(u'effect', 1754.0)\n",
      "(u'compani', 1753.0)\n",
      "(u'life', 1743.0)\n",
      "(u'treatment', 1739.0)\n",
      "(u'dr', 1725.0)\n",
      "(u'program', 1691.0)\n",
      "(u'parent', 1665.0)\n",
      "(u'problem', 1657.0)\n",
      "(u'student', 1656.0)\n",
      "(u'risk', 1623.0)\n",
      "(u'increas', 1553.0)\n",
      "(u'develop', 1532.0)\n",
      "(u'scienc', 1493.0)\n",
      "(u'death', 1451.0)\n",
      "(u'system', 1442.0)\n",
      "(u'home', 1437.0)\n",
      "(u'pain', 1431.0)\n",
      "(u'feel', 1407.0)\n",
      "(u'center', 1403.0)\n",
      "(u'result', 1391.0)\n",
      "(u'lot', 1366.0)\n",
      "(u'number', 1348.0)\n",
      "(u'age', 1340.0)\n",
      "(u'high', 1339.0)\n",
      "(u'eat', 1331.0)\n",
      "(u'bodi', 1295.0)\n",
      "(u'chang', 1285.0)\n",
      "(u'vaccin', 1253.0)\n",
      "(u'organ', 1239.0)\n",
      "(u'lead', 1228.0)\n",
      "(u'scientist', 1221.0)\n",
      "(u'million', 1209.0)\n",
      "(u'didnt', 1205.0)\n",
      "(u'rate', 1203.0)\n",
      "(u'experi', 1201.0)\n",
      "(u'data', 1198.0)\n",
      "(u'commun', 1194.0)\n",
      "(u'babi', 1191.0)\n",
      "(u'theyr', 1190.0)\n",
      "(u'kid', 1185.0)\n",
      "(u'opioid', 1173.0)\n",
      "(u'die', 1153.0)\n",
      "(u'learn', 1128.0)\n",
      "(u'import', 1105.0)\n",
      "(u'provid', 1103.0)\n",
      "(u'im', 1103.0)\n",
      "(u'cell', 1089.0)\n",
      "(u'men', 1087.0)\n",
      "(u'medicin', 1086.0)\n",
      "(u'plan', 1082.0)\n",
      "(u'blood', 1073.0)\n",
      "(u'product', 1071.0)\n",
      "(u'control', 1069.0)\n",
      "(u'level', 1049.0)\n",
      "(u'cost', 1034.0)\n",
      "(u'give', 1027.0)\n",
      "(u'child', 1025.0)\n",
      "(u'educ', 1018.0)\n",
      "(u'requir', 1014.0)\n",
      "(u'treat', 1014.0)\n",
      "(u'take', 1005.0)\n",
      "(u'clinic', 1005.0)\n",
      "(u'prevent', 1000.0)\n",
      "(u'heart', 996.0)\n",
      "(u'suggest', 987.0)\n",
      "(u'your', 982.0)\n",
      "(u'fund', 981.0)\n",
      "(u'job', 976.0)\n",
      "(u'help', 970.0)\n",
      "(u'mother', 968.0)\n",
      "(u'doesnt', 957.0)\n",
      "(u'place', 950.0)\n",
      "(u'addict', 944.0)\n",
      "(u'author', 943.0)\n",
      "(u'insur', 942.0)\n",
      "(u'benefit', 933.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[14]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'water', 2968.0)\n",
      "(u'climat', 1856.0)\n",
      "(u'citi', 1717.0)\n",
      "(u'space', 1705.0)\n",
      "(u'chang', 1591.0)\n",
      "(u'scientist', 1500.0)\n",
      "(u'area', 1459.0)\n",
      "(u'research', 1444.0)\n",
      "(u'human', 1337.0)\n",
      "(u'earth', 1279.0)\n",
      "(u'land', 1275.0)\n",
      "(u'found', 1247.0)\n",
      "(u'studi', 1214.0)\n",
      "(u'fire', 1190.0)\n",
      "(u'home', 1182.0)\n",
      "(u'million', 1175.0)\n",
      "(u'system', 1155.0)\n",
      "(u'univers', 1153.0)\n",
      "(u'build', 1141.0)\n",
      "(u'planet', 1087.0)\n",
      "(u'compani', 1040.0)\n",
      "(u'life', 1013.0)\n",
      "(u'natur', 995.0)\n",
      "(u'plan', 986.0)\n",
      "(u'find', 981.0)\n",
      "(u'park', 978.0)\n",
      "(u'mile', 975.0)\n",
      "(u'sea', 974.0)\n",
      "(u'place', 962.0)\n",
      "(u'nasa', 956.0)\n",
      "(u'scienc', 925.0)\n",
      "(u'ocean', 924.0)\n",
      "(u'anim', 923.0)\n",
      "(u'energi', 907.0)\n",
      "(u'speci', 887.0)\n",
      "(u'power', 884.0)\n",
      "(u'global', 868.0)\n",
      "(u'warm', 862.0)\n",
      "(u'california', 862.0)\n",
      "(u'air', 851.0)\n",
      "(u'big', 849.0)\n",
      "(u'plant', 843.0)\n",
      "(u'project', 842.0)\n",
      "(u'hour', 835.0)\n",
      "(u'temperatur', 819.0)\n",
      "(u'servic', 816.0)\n",
      "(u'lot', 812.0)\n",
      "(u'weather', 812.0)\n",
      "(u'develop', 808.0)\n",
      "(u'ice', 786.0)\n",
      "(u'protect', 785.0)\n",
      "(u'level', 779.0)\n",
      "(u'storm', 777.0)\n",
      "(u'river', 776.0)\n",
      "(u'local', 768.0)\n",
      "(u'emerg', 764.0)\n",
      "(u'island', 760.0)\n",
      "(u'percent', 754.0)\n",
      "(u'resid', 750.0)\n",
      "(u'turn', 749.0)\n",
      "(u'small', 747.0)\n",
      "(u'south', 743.0)\n",
      "(u'car', 743.0)\n",
      "(u'team', 741.0)\n",
      "(u'ago', 740.0)\n",
      "(u'commun', 739.0)\n",
      "(u'close', 738.0)\n",
      "(u'feet', 737.0)\n",
      "(u'flood', 736.0)\n",
      "(u'agenc', 734.0)\n",
      "(u'region', 730.0)\n",
      "(u'manag', 724.0)\n",
      "(u'fish', 720.0)\n",
      "(u'problem', 708.0)\n",
      "(u'author', 707.0)\n",
      "(u'moon', 706.0)\n",
      "(u'north', 703.0)\n",
      "(u'flight', 691.0)\n",
      "(u'record', 691.0)\n",
      "(u'larg', 688.0)\n",
      "(u'data', 683.0)\n",
      "(u'open', 679.0)\n",
      "(u'expect', 679.0)\n",
      "(u'happen', 677.0)\n",
      "(u'high', 674.0)\n",
      "(u'station', 674.0)\n",
      "(u'road', 674.0)\n",
      "(u'site', 672.0)\n",
      "(u'run', 665.0)\n",
      "(u'set', 664.0)\n",
      "(u'tree', 655.0)\n",
      "(u'feder', 650.0)\n",
      "(u'launch', 642.0)\n",
      "(u'technolog', 641.0)\n",
      "(u'damag', 638.0)\n",
      "(u'snow', 637.0)\n",
      "(u'industri', 637.0)\n",
      "(u'design', 636.0)\n",
      "(u'creat', 636.0)\n",
      "(u'oper', 635.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[34]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'republican', 5876.0)\n",
      "(u'bill', 5447.0)\n",
      "(u'health', 5237.0)\n",
      "(u'care', 4345.0)\n",
      "(u'insur', 3811.0)\n",
      "(u'plan', 3550.0)\n",
      "(u'tax', 3511.0)\n",
      "(u'obamacar', 3190.0)\n",
      "(u'vote', 2459.0)\n",
      "(u'democrat', 2188.0)\n",
      "(u'medicaid', 1991.0)\n",
      "(u'senat', 1877.0)\n",
      "(u'ryan', 1791.0)\n",
      "(u'repeal', 1670.0)\n",
      "(u'coverag', 1655.0)\n",
      "(u'pass', 1632.0)\n",
      "(u'act', 1608.0)\n",
      "(u'legisl', 1599.0)\n",
      "(u'percent', 1497.0)\n",
      "(u'gop', 1446.0)\n",
      "(u'conserv', 1446.0)\n",
      "(u'cost', 1400.0)\n",
      "(u'member', 1399.0)\n",
      "(u'white', 1390.0)\n",
      "(u'fund', 1344.0)\n",
      "(u'caucu', 1342.0)\n",
      "(u'law', 1315.0)\n",
      "(u'afford', 1308.0)\n",
      "(u'freedom', 1240.0)\n",
      "(u'cut', 1239.0)\n",
      "(u'budget', 1191.0)\n",
      "(u'million', 1150.0)\n",
      "(u'congress', 1130.0)\n",
      "(u'feder', 1128.0)\n",
      "(u'premium', 1118.0)\n",
      "(u'spend', 1068.0)\n",
      "(u'pay', 1043.0)\n",
      "(u'program', 1033.0)\n",
      "(u'replac', 1030.0)\n",
      "(u'administr', 1026.0)\n",
      "(u'leader', 1012.0)\n",
      "(u'polici', 1009.0)\n",
      "(u'reform', 942.0)\n",
      "(u'major', 932.0)\n",
      "(u'benefit', 919.0)\n",
      "(u'propos', 918.0)\n",
      "(u'requir', 887.0)\n",
      "(u'parti', 841.0)\n",
      "(u'healthcar', 817.0)\n",
      "(u'individu', 801.0)\n",
      "(u'market', 791.0)\n",
      "(u'cover', 787.0)\n",
      "(u'paul', 775.0)\n",
      "(u'condit', 772.0)\n",
      "(u'speaker', 759.0)\n",
      "(u'rate', 743.0)\n",
      "(u'rep', 742.0)\n",
      "(u'promis', 725.0)\n",
      "(u'ahca', 718.0)\n",
      "(u'system', 715.0)\n",
      "(u'moder', 714.0)\n",
      "(u'congression', 695.0)\n",
      "(u'increas', 679.0)\n",
      "(u'provid', 668.0)\n",
      "(u'aca', 648.0)\n",
      "(u'price', 644.0)\n",
      "(u'money', 623.0)\n",
      "(u'famili', 622.0)\n",
      "(u'tuesday', 619.0)\n",
      "(u'chang', 616.0)\n",
      "(u'deal', 615.0)\n",
      "(u'repres', 603.0)\n",
      "(u'servic', 598.0)\n",
      "(u'meet', 598.0)\n",
      "(u'thursday', 597.0)\n",
      "(u'obama', 594.0)\n",
      "(u'wall', 590.0)\n",
      "(u'effort', 584.0)\n",
      "(u'billion', 579.0)\n",
      "(u'lawmak', 576.0)\n",
      "(u'incom', 576.0)\n",
      "(u'subsidi', 556.0)\n",
      "(u'washington', 544.0)\n",
      "(u'committe', 538.0)\n",
      "(u'fail', 538.0)\n",
      "(u'offer', 531.0)\n",
      "(u'lose', 529.0)\n",
      "(u'number', 522.0)\n",
      "(u'expans', 515.0)\n",
      "(u'cbo', 514.0)\n",
      "(u'compani', 505.0)\n",
      "(u'credit', 504.0)\n",
      "(u'negoti', 502.0)\n",
      "(u'rule', 496.0)\n",
      "(u'friday', 495.0)\n",
      "(u'lower', 492.0)\n",
      "(u'sign', 484.0)\n",
      "(u'problem', 482.0)\n",
      "(u'give', 479.0)\n",
      "(u'medic', 473.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[312]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'comey', 5912.0)\n",
      "(u'investig', 4611.0)\n",
      "(u'fbi', 3045.0)\n",
      "(u'russia', 2183.0)\n",
      "(u'russian', 2056.0)\n",
      "(u'director', 1968.0)\n",
      "(u'flynn', 1776.0)\n",
      "(u'fire', 1726.0)\n",
      "(u'white', 1633.0)\n",
      "(u'committe', 1528.0)\n",
      "(u'senat', 1523.0)\n",
      "(u'intellig', 1482.0)\n",
      "(u'attorney', 1418.0)\n",
      "(u'justic', 1374.0)\n",
      "(u'mueller', 1234.0)\n",
      "(u'session', 1180.0)\n",
      "(u'elect', 1062.0)\n",
      "(u'depart', 1035.0)\n",
      "(u'counsel', 1012.0)\n",
      "(u'ask', 1005.0)\n",
      "(u'meet', 974.0)\n",
      "(u'special', 973.0)\n",
      "(u'convers', 960.0)\n",
      "(u'testimoni', 861.0)\n",
      "(u'jame', 844.0)\n",
      "(u'secur', 843.0)\n",
      "(u'inform', 841.0)\n",
      "(u'democrat', 836.0)\n",
      "(u'probe', 780.0)\n",
      "(u'rosenstein', 768.0)\n",
      "(u'advis', 707.0)\n",
      "(u'clinton', 687.0)\n",
      "(u'republican', 671.0)\n",
      "(u'hear', 655.0)\n",
      "(u'memo', 651.0)\n",
      "(u'obstruct', 650.0)\n",
      "(u'administr', 643.0)\n",
      "(u'matter', 616.0)\n",
      "(u'statement', 596.0)\n",
      "(u'washington', 586.0)\n",
      "(u'law', 585.0)\n",
      "(u'deputi', 553.0)\n",
      "(u'decis', 547.0)\n",
      "(u'cnn', 545.0)\n",
      "(u'leak', 539.0)\n",
      "(u'appoint', 528.0)\n",
      "(u'press', 524.0)\n",
      "(u'request', 523.0)\n",
      "(u'post', 522.0)\n",
      "(u'collus', 513.0)\n",
      "(u'testifi', 507.0)\n",
      "(u'thursday', 489.0)\n",
      "(u'discuss', 488.0)\n",
      "(u'congress', 479.0)\n",
      "(u'tweet', 478.0)\n",
      "(u'case', 476.0)\n",
      "(u'commun', 475.0)\n",
      "(u'sourc', 472.0)\n",
      "(u'yate', 470.0)\n",
      "(u'michael', 468.0)\n",
      "(u'presidenti', 468.0)\n",
      "(u'document', 458.0)\n",
      "(u'act', 455.0)\n",
      "(u'crimin', 454.0)\n",
      "(u'stori', 448.0)\n",
      "(u'kushner', 444.0)\n",
      "(u'evid', 443.0)\n",
      "(u'legal', 433.0)\n",
      "(u'interfer', 424.0)\n",
      "(u'alleg', 424.0)\n",
      "(u'sen', 421.0)\n",
      "(u'tuesday', 420.0)\n",
      "(u'email', 419.0)\n",
      "(u'agenc', 418.0)\n",
      "(u'hope', 413.0)\n",
      "(u'concern', 411.0)\n",
      "(u'record', 401.0)\n",
      "(u'foreign', 397.0)\n",
      "(u'fact', 396.0)\n",
      "(u'\\t', 396.0)\n",
      "(u'privat', 394.0)\n",
      "(u'talk', 388.0)\n",
      "(u'prosecutor', 385.0)\n",
      "(u'answer', 384.0)\n",
      "(u'didnt', 383.0)\n",
      "(u'interview', 381.0)\n",
      "(u'team', 380.0)\n",
      "(u'comment', 377.0)\n",
      "(u'associ', 371.0)\n",
      "(u'close', 370.0)\n",
      "(u'confirm', 369.0)\n",
      "(u'clear', 366.0)\n",
      "(u'media', 364.0)\n",
      "(u'tape', 360.0)\n",
      "(u'independ', 359.0)\n",
      "(u'lawyer', 356.0)\n",
      "(u'member', 348.0)\n",
      "(u'classifi', 344.0)\n",
      "(u'reason', 344.0)\n",
      "(u'clapper', 343.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[561]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'north', 5474.0)\n",
      "(u'korea', 5077.0)\n",
      "(u'missil', 2363.0)\n",
      "(u'china', 2009.0)\n",
      "(u'korean', 1885.0)\n",
      "(u'nuclear', 1776.0)\n",
      "(u'south', 1518.0)\n",
      "(u'militari', 1207.0)\n",
      "(u'test', 1172.0)\n",
      "(u'qatar', 1085.0)\n",
      "(u'kim', 957.0)\n",
      "(u'pyongyang', 899.0)\n",
      "(u'administr', 868.0)\n",
      "(u'weapon', 781.0)\n",
      "(u'forc', 741.0)\n",
      "(u'secur', 722.0)\n",
      "(u'launch', 715.0)\n",
      "(u'region', 706.0)\n",
      "(u'defens', 695.0)\n",
      "(u'washington', 683.0)\n",
      "(u'strike', 664.0)\n",
      "(u'chines', 644.0)\n",
      "(u'foreign', 614.0)\n",
      "(u'sanction', 595.0)\n",
      "(u'war', 594.0)\n",
      "(u'iran', 586.0)\n",
      "(u'program', 578.0)\n",
      "(u'leader', 573.0)\n",
      "(u'alli', 570.0)\n",
      "(u'polici', 562.0)\n",
      "(u'ballist', 538.0)\n",
      "(u'regim', 538.0)\n",
      "(u'attack', 533.0)\n",
      "(u'warmbier', 524.0)\n",
      "(u'threat', 507.0)\n",
      "(u'saudi', 495.0)\n",
      "(u'meet', 493.0)\n",
      "(u'syria', 492.0)\n",
      "(u'diplomat', 488.0)\n",
      "(u'tillerson', 483.0)\n",
      "(u'statement', 478.0)\n",
      "(u'deal', 460.0)\n",
      "(u'japan', 449.0)\n",
      "(u'peninsula', 440.0)\n",
      "(u'action', 437.0)\n",
      "(u'white', 432.0)\n",
      "(u'secretari', 431.0)\n",
      "(u'intern', 430.0)\n",
      "(u'beij', 429.0)\n",
      "(u'power', 402.0)\n",
      "(u'system', 401.0)\n",
      "(u'develop', 398.0)\n",
      "(u'talk', 394.0)\n",
      "(u'russia', 388.0)\n",
      "(u'wednesday', 378.0)\n",
      "(u'tuesday', 372.0)\n",
      "(u'gulf', 368.0)\n",
      "(u'oper', 360.0)\n",
      "(u'warn', 354.0)\n",
      "(u'arabia', 350.0)\n",
      "(u'pressur', 350.0)\n",
      "(u'council', 346.0)\n",
      "(u'capabl', 346.0)\n",
      "(u'seoul', 340.0)\n",
      "(u'moon', 335.0)\n",
      "(u'tension', 332.0)\n",
      "(u'respons', 331.0)\n",
      "(u'deploy', 328.0)\n",
      "(u'jong', 328.0)\n",
      "(u'sea', 325.0)\n",
      "(u'russian', 322.0)\n",
      "(u'cnn', 320.0)\n",
      "(u'relat', 316.0)\n",
      "(u'aircraft', 307.0)\n",
      "(u'minist', 305.0)\n",
      "(u'air', 300.0)\n",
      "(u'trade', 299.0)\n",
      "(u'arab', 299.0)\n",
      "(u'effort', 299.0)\n",
      "(u'obama', 297.0)\n",
      "(u'xi', 296.0)\n",
      "(u'econom', 294.0)\n",
      "(u'visit', 292.0)\n",
      "(u'base', 291.0)\n",
      "(u'conduct', 291.0)\n",
      "(u'agenc', 277.0)\n",
      "(u'depart', 276.0)\n",
      "(u'import', 275.0)\n",
      "(u'monday', 270.0)\n",
      "(u'ministri', 269.0)\n",
      "(u'icbm', 269.0)\n",
      "(u'tie', 266.0)\n",
      "(u'carrier', 265.0)\n",
      "(u'concern', 264.0)\n",
      "(u'close', 262.0)\n",
      "(u'plan', 259.0)\n",
      "(u'\\t', 258.0)\n",
      "(u'reach', 258.0)\n",
      "(u'sunday', 250.0)\n",
      "(u'syrian', 250.0)\n"
     ]
    }
   ],
   "source": [
    "# visualize the word distribution of sepecified cluster:\n",
    "\n",
    "# for cluster \n",
    "specified_cls = particle.clusters[435]\n",
    "word_distribution = specified_cls.word_distribution\n",
    "top_num = 100\n",
    "top_word_idx = np.argsort(word_distribution)[::-1][:top_num]\n",
    "for word_id in top_word_idx:\n",
    "    print(id2word[str(word_id)], word_distribution[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
